{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b2cc5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: ['__header__', '__version__', '__globals__', 'unitdata', 'samples', 'spkmat', 'startOrder', 'start']\n",
      "unitdata fields: ['units']\n",
      "units: shape (52,)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import pickle\n",
    "import os\n",
    "file_path = '/Users/bytedance/Documents/PHD/datasets/2016_Eichenbaum/AJF023/CD1/AJF023CD1SpksEvsSimple.mat'\n",
    "\n",
    "mat = scipy.io.loadmat(file_path, struct_as_record=False, squeeze_me=True)\n",
    "\n",
    "print(\"Variables:\", list(mat.keys()))\n",
    "\n",
    "unitdata = mat['unitdata']\n",
    "\n",
    "print(\"unitdata fields:\", unitdata._fieldnames)\n",
    "\n",
    "for field in unitdata._fieldnames:\n",
    "    data = getattr(unitdata, field)\n",
    "    print(f\"{field}: shape {getattr(data, 'shape', 'scalar')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef9483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51 session files\n",
      "\n",
      "================================================================================\n",
      "SESSION STATISTICS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total sessions: 51\n",
      "Total units across all sessions: 1757\n",
      "Total spikes across all sessions: 19,610,623\n",
      "\n",
      "Number of animals: 5\n",
      "\n",
      "Per-animal summary:\n",
      "  AJF016: 11 sessions, 132 units, 2,977,298 spikes\n",
      "  AJF023: 11 sessions, 432 units, 6,998,199 spikes\n",
      "  AJF025: 9 sessions, 315 units, 4,751,167 spikes\n",
      "  AJF027: 10 sessions, 421 units, 2,521,994 spikes\n",
      "  AJF033: 10 sessions, 457 units, 2,361,965 spikes\n",
      "\n",
      "Units per session:\n",
      "  Mean: 34.5\n",
      "  Median: 35.0\n",
      "  Min: 6\n",
      "  Max: 70\n",
      "  Std: 16.4\n",
      "\n",
      "Mean firing rate per session (Hz):\n",
      "  Mean: 2.43\n",
      "  Median: 2.16\n",
      "  Min: 0.37\n",
      "  Max: 6.75\n",
      "\n",
      "Session duration (seconds):\n",
      "  Mean: 6001.7\n",
      "  Median: 5203.7\n",
      "  Min: 2781.7\n",
      "  Max: 13095.3\n",
      "\n",
      "Active units per session (units with spikes):\n",
      "  Mean: 34.5\n",
      "  Median: 35.0\n",
      "  Min: 6\n",
      "  Max: 70\n",
      "\n",
      "================================================================================\n",
      "First 10 sessions detail:\n",
      "================================================================================\n",
      "1. AJF016_CD1: 17 units, 418,796 spikes, FR=4.12 Hz, duration=5996.0s\n",
      "2. AJF016_CD2: 13 units, 209,784 spikes, FR=3.07 Hz, duration=5292.8s\n",
      "3. AJF016_CD3: 11 units, 362,608 spikes, FR=6.75 Hz, duration=4885.7s\n",
      "4. AJF016_CD3EF1: 10 units, 523,376 spikes, FR=5.38 Hz, duration=11148.6s\n",
      "5. AJF016_CDEF1: 20 units, 189,429 spikes, FR=2.16 Hz, duration=4848.4s\n",
      "6. AJF016_CDEF2: 13 units, 174,500 spikes, FR=2.72 Hz, duration=4935.9s\n",
      "7. AJF016_CDEF3: 6 units, 234,131 spikes, FR=6.40 Hz, duration=6113.1s\n",
      "8. AJF016_EF1: 14 units, 446,821 spikes, FR=5.15 Hz, duration=6202.8s\n",
      "9. AJF016_EF2: 9 units, 180,679 spikes, FR=3.85 Hz, duration=5225.1s\n",
      "10. AJF016_EF3: 10 units, 196,026 spikes, FR=4.07 Hz, duration=4857.2s\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import scipy.io\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Find all SpksEvsSimple.mat files\n",
    "base_dir = '/Users/bytedance/Documents/PHD/datasets/2016_Eichenbaum'\n",
    "mat_files = glob.glob(os.path.join(base_dir, '**', '*SpksEvsSimple.mat'), recursive=True)\n",
    "mat_files.sort()\n",
    "\n",
    "print(f\"Found {len(mat_files)} session files\\n\")\n",
    "\n",
    "# Statistics storage\n",
    "session_stats = []\n",
    "\n",
    "# Process each session - rolling memory management\n",
    "for file_path in mat_files:\n",
    "    mat = None\n",
    "    units = None\n",
    "    try:\n",
    "        # Load one file at a time\n",
    "        mat = scipy.io.loadmat(file_path, struct_as_record=False, squeeze_me=True)\n",
    "        \n",
    "        if 'unitdata' not in mat:\n",
    "            print(f\"Skipping {file_path}: no unitdata\")\n",
    "            del mat\n",
    "            gc.collect()\n",
    "            continue\n",
    "            \n",
    "        units = mat['unitdata'].units\n",
    "        \n",
    "        # Extract session info from path\n",
    "        path_parts = Path(file_path).parts\n",
    "        animal_id = path_parts[-3] if len(path_parts) >= 3 else \"unknown\"\n",
    "        session_id = path_parts[-2] if len(path_parts) >= 2 else \"unknown\"\n",
    "        session_name = f\"{animal_id}_{session_id}\"\n",
    "        \n",
    "        # Collect statistics for this session\n",
    "        n_units = len(units)\n",
    "        total_spikes = 0\n",
    "        firing_rates = []\n",
    "        session_duration = 0\n",
    "        \n",
    "        for unit in units:\n",
    "            if hasattr(unit, 'ts'):\n",
    "                spiketimes = unit.ts.flatten()\n",
    "                n_spikes = len(spiketimes)\n",
    "                total_spikes += n_spikes\n",
    "                \n",
    "                if n_spikes > 0:\n",
    "                    duration = spiketimes.max() - spiketimes.min() if len(spiketimes) > 1 else 0\n",
    "                    session_duration = max(session_duration, duration)\n",
    "                    firing_rate = n_spikes / duration if duration > 0 else 0\n",
    "                    firing_rates.append(firing_rate)\n",
    "                # Clear spiketimes from memory immediately after use\n",
    "                del spiketimes\n",
    "        \n",
    "        mean_fr = np.mean(firing_rates) if firing_rates else 0\n",
    "        median_fr = np.median(firing_rates) if firing_rates else 0\n",
    "        \n",
    "        stats = {\n",
    "            'session': session_name,\n",
    "            'animal': animal_id,\n",
    "            'session_id': session_id,\n",
    "            'file_path': file_path,\n",
    "            'n_units': n_units,\n",
    "            'total_spikes': total_spikes,\n",
    "            'mean_firing_rate': mean_fr,\n",
    "            'median_firing_rate': median_fr,\n",
    "            'session_duration': session_duration,\n",
    "            'n_active_units': len(firing_rates)\n",
    "        }\n",
    "        session_stats.append(stats)\n",
    "        \n",
    "        # Clear intermediate variables\n",
    "        del firing_rates\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "    finally:\n",
    "        # Explicitly release memory after processing each file\n",
    "        if units is not None:\n",
    "            del units\n",
    "        if mat is not None:\n",
    "            del mat\n",
    "        # Force garbage collection to free memory\n",
    "        gc.collect()\n",
    "\n",
    "# Convert to structured format for easier analysis\n",
    "print(\"=\"*80)\n",
    "print(\"SESSION STATISTICS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Overall statistics\n",
    "print(f\"\\nTotal sessions: {len(session_stats)}\")\n",
    "print(f\"Total units across all sessions: {sum(s['n_units'] for s in session_stats)}\")\n",
    "print(f\"Total spikes across all sessions: {sum(s['total_spikes'] for s in session_stats):,}\")\n",
    "\n",
    "# Per-animal statistics\n",
    "animals = {}\n",
    "for stats in session_stats:\n",
    "    animal = stats['animal']\n",
    "    if animal not in animals:\n",
    "        animals[animal] = {'sessions': 0, 'units': 0, 'spikes': 0}\n",
    "    animals[animal]['sessions'] += 1\n",
    "    animals[animal]['units'] += stats['n_units']\n",
    "    animals[animal]['spikes'] += stats['total_spikes']\n",
    "\n",
    "print(f\"\\nNumber of animals: {len(animals)}\")\n",
    "print(\"\\nPer-animal summary:\")\n",
    "for animal, data in sorted(animals.items()):\n",
    "    print(f\"  {animal}: {data['sessions']} sessions, {data['units']} units, {data['spikes']:,} spikes\")\n",
    "\n",
    "# Unit count statistics\n",
    "unit_counts = [s['n_units'] for s in session_stats]\n",
    "print(f\"\\nUnits per session:\")\n",
    "print(f\"  Mean: {np.mean(unit_counts):.1f}\")\n",
    "print(f\"  Median: {np.median(unit_counts):.1f}\")\n",
    "print(f\"  Min: {np.min(unit_counts)}\")\n",
    "print(f\"  Max: {np.max(unit_counts)}\")\n",
    "print(f\"  Std: {np.std(unit_counts):.1f}\")\n",
    "\n",
    "# Firing rate statistics\n",
    "firing_rates_all = [s['mean_firing_rate'] for s in session_stats if s['mean_firing_rate'] > 0]\n",
    "if firing_rates_all:\n",
    "    print(f\"\\nMean firing rate per session (Hz):\")\n",
    "    print(f\"  Mean: {np.mean(firing_rates_all):.2f}\")\n",
    "    print(f\"  Median: {np.median(firing_rates_all):.2f}\")\n",
    "    print(f\"  Min: {np.min(firing_rates_all):.2f}\")\n",
    "    print(f\"  Max: {np.max(firing_rates_all):.2f}\")\n",
    "\n",
    "# Session duration statistics\n",
    "durations = [s['session_duration'] for s in session_stats if s['session_duration'] > 0]\n",
    "if durations:\n",
    "    print(f\"\\nSession duration (seconds):\")\n",
    "    print(f\"  Mean: {np.mean(durations):.1f}\")\n",
    "    print(f\"  Median: {np.median(durations):.1f}\")\n",
    "    print(f\"  Min: {np.min(durations):.1f}\")\n",
    "    print(f\"  Max: {np.max(durations):.1f}\")\n",
    "\n",
    "# Active units statistics\n",
    "active_units = [s['n_active_units'] for s in session_stats]\n",
    "print(f\"\\nActive units per session (units with spikes):\")\n",
    "print(f\"  Mean: {np.mean(active_units):.1f}\")\n",
    "print(f\"  Median: {np.median(active_units):.1f}\")\n",
    "print(f\"  Min: {np.min(active_units)}\")\n",
    "print(f\"  Max: {np.max(active_units)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"First 10 sessions detail:\")\n",
    "print(\"=\"*80)\n",
    "for i, stats in enumerate(session_stats[:10]):\n",
    "    print(f\"{i+1}. {stats['session']}: {stats['n_units']} units, \"\n",
    "          f\"{stats['total_spikes']:,} spikes, \"\n",
    "          f\"FR={stats['mean_firing_rate']:.2f} Hz, \"\n",
    "          f\"duration={stats['session_duration']:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "771cb92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 17 neurons to data/eichenbaum2016/AJF016/CD1/AJF016_CD1.pkl and raster to data/eichenbaum2016/AJF016/CD1/AJF016_CD1_spike_raster.png\n",
      "Saved 13 neurons to data/eichenbaum2016/AJF016/CD2/AJF016_CD2.pkl and raster to data/eichenbaum2016/AJF016/CD2/AJF016_CD2_spike_raster.png\n",
      "Saved 11 neurons to data/eichenbaum2016/AJF016/CD3/AJF016_CD3.pkl and raster to data/eichenbaum2016/AJF016/CD3/AJF016_CD3_spike_raster.png\n",
      "Saved 10 neurons to data/eichenbaum2016/AJF016/CD3EF1/AJF016_CD3EF1.pkl and raster to data/eichenbaum2016/AJF016/CD3EF1/AJF016_CD3EF1_spike_raster.png\n",
      "Saved 20 neurons to data/eichenbaum2016/AJF016/CDEF1/AJF016_CDEF1.pkl and raster to data/eichenbaum2016/AJF016/CDEF1/AJF016_CDEF1_spike_raster.png\n",
      "Saved 13 neurons to data/eichenbaum2016/AJF016/CDEF2/AJF016_CDEF2.pkl and raster to data/eichenbaum2016/AJF016/CDEF2/AJF016_CDEF2_spike_raster.png\n",
      "Saved 6 neurons to data/eichenbaum2016/AJF016/CDEF3/AJF016_CDEF3.pkl and raster to data/eichenbaum2016/AJF016/CDEF3/AJF016_CDEF3_spike_raster.png\n",
      "Saved 14 neurons to data/eichenbaum2016/AJF016/EF1/AJF016_EF1.pkl and raster to data/eichenbaum2016/AJF016/EF1/AJF016_EF1_spike_raster.png\n",
      "Saved 9 neurons to data/eichenbaum2016/AJF016/EF2/AJF016_EF2.pkl and raster to data/eichenbaum2016/AJF016/EF2/AJF016_EF2_spike_raster.png\n",
      "Saved 10 neurons to data/eichenbaum2016/AJF016/EF3/AJF016_EF3.pkl and raster to data/eichenbaum2016/AJF016/EF3/AJF016_EF3_spike_raster.png\n",
      "Saved 9 neurons to data/eichenbaum2016/AJF016/EF3CDEF1/AJF016_EF3CDEF1.pkl and raster to data/eichenbaum2016/AJF016/EF3CDEF1/AJF016_EF3CDEF1_spike_raster.png\n",
      "Saved 52 neurons to data/eichenbaum2016/AJF023/CD1/AJF023_CD1.pkl and raster to data/eichenbaum2016/AJF023/CD1/AJF023_CD1_spike_raster.png\n",
      "Saved 45 neurons to data/eichenbaum2016/AJF023/CD2/AJF023_CD2.pkl and raster to data/eichenbaum2016/AJF023/CD2/AJF023_CD2_spike_raster.png\n",
      "Saved 47 neurons to data/eichenbaum2016/AJF023/CD3/AJF023_CD3.pkl and raster to data/eichenbaum2016/AJF023/CD3/AJF023_CD3_spike_raster.png\n",
      "Saved 29 neurons to data/eichenbaum2016/AJF023/CD3EF1/AJF023_CD3EF1.pkl and raster to data/eichenbaum2016/AJF023/CD3EF1/AJF023_CD3EF1_spike_raster.png\n",
      "Saved 35 neurons to data/eichenbaum2016/AJF023/CDEF1/AJF023_CDEF1.pkl and raster to data/eichenbaum2016/AJF023/CDEF1/AJF023_CDEF1_spike_raster.png\n",
      "Saved 31 neurons to data/eichenbaum2016/AJF023/CDEF2/AJF023_CDEF2.pkl and raster to data/eichenbaum2016/AJF023/CDEF2/AJF023_CDEF2_spike_raster.png\n",
      "Saved 47 neurons to data/eichenbaum2016/AJF023/CDEF3/AJF023_CDEF3.pkl and raster to data/eichenbaum2016/AJF023/CDEF3/AJF023_CDEF3_spike_raster.png\n",
      "Saved 56 neurons to data/eichenbaum2016/AJF023/EF1/AJF023_EF1.pkl and raster to data/eichenbaum2016/AJF023/EF1/AJF023_EF1_spike_raster.png\n",
      "Saved 35 neurons to data/eichenbaum2016/AJF023/EF2/AJF023_EF2.pkl and raster to data/eichenbaum2016/AJF023/EF2/AJF023_EF2_spike_raster.png\n",
      "Saved 33 neurons to data/eichenbaum2016/AJF023/EF3/AJF023_EF3.pkl and raster to data/eichenbaum2016/AJF023/EF3/AJF023_EF3_spike_raster.png\n",
      "Saved 22 neurons to data/eichenbaum2016/AJF023/EF3CDEF1/AJF023_EF3CDEF1.pkl and raster to data/eichenbaum2016/AJF023/EF3CDEF1/AJF023_EF3CDEF1_spike_raster.png\n",
      "Saved 29 neurons to data/eichenbaum2016/AJF025/CD1/AJF025_CD1.pkl and raster to data/eichenbaum2016/AJF025/CD1/AJF025_CD1_spike_raster.png\n",
      "Saved 30 neurons to data/eichenbaum2016/AJF025/CD2/AJF025_CD2.pkl and raster to data/eichenbaum2016/AJF025/CD2/AJF025_CD2_spike_raster.png\n",
      "Saved 31 neurons to data/eichenbaum2016/AJF025/CD3/AJF025_CD3.pkl and raster to data/eichenbaum2016/AJF025/CD3/AJF025_CD3_spike_raster.png\n",
      "Saved 36 neurons to data/eichenbaum2016/AJF025/CDEF1/AJF025_CDEF1.pkl and raster to data/eichenbaum2016/AJF025/CDEF1/AJF025_CDEF1_spike_raster.png\n",
      "Saved 44 neurons to data/eichenbaum2016/AJF025/CDEF2/AJF025_CDEF2.pkl and raster to data/eichenbaum2016/AJF025/CDEF2/AJF025_CDEF2_spike_raster.png\n",
      "Saved 40 neurons to data/eichenbaum2016/AJF025/CDEF3/AJF025_CDEF3.pkl and raster to data/eichenbaum2016/AJF025/CDEF3/AJF025_CDEF3_spike_raster.png\n",
      "Saved 19 neurons to data/eichenbaum2016/AJF025/EF1/AJF025_EF1.pkl and raster to data/eichenbaum2016/AJF025/EF1/AJF025_EF1_spike_raster.png\n",
      "Saved 55 neurons to data/eichenbaum2016/AJF025/EF3/AJF025_EF3.pkl and raster to data/eichenbaum2016/AJF025/EF3/AJF025_EF3_spike_raster.png\n",
      "Saved 31 neurons to data/eichenbaum2016/AJF025/EF3CDEF1/AJF025_EF3CDEF1.pkl and raster to data/eichenbaum2016/AJF025/EF3CDEF1/AJF025_EF3CDEF1_spike_raster.png\n",
      "Saved 29 neurons to data/eichenbaum2016/AJF027/CD1/AJF027_CD1.pkl and raster to data/eichenbaum2016/AJF027/CD1/AJF027_CD1_spike_raster.png\n",
      "Saved 42 neurons to data/eichenbaum2016/AJF027/CD2/AJF027_CD2.pkl and raster to data/eichenbaum2016/AJF027/CD2/AJF027_CD2_spike_raster.png\n",
      "Saved 29 neurons to data/eichenbaum2016/AJF027/CD3/AJF027_CD3.pkl and raster to data/eichenbaum2016/AJF027/CD3/AJF027_CD3_spike_raster.png\n",
      "Saved 9 neurons to data/eichenbaum2016/AJF027/CD3EF1/AJF027_CD3EF1.pkl and raster to data/eichenbaum2016/AJF027/CD3EF1/AJF027_CD3EF1_spike_raster.png\n",
      "Saved 50 neurons to data/eichenbaum2016/AJF027/CDEF1/AJF027_CDEF1.pkl and raster to data/eichenbaum2016/AJF027/CDEF1/AJF027_CDEF1_spike_raster.png\n",
      "Saved 70 neurons to data/eichenbaum2016/AJF027/CDEF2/AJF027_CDEF2.pkl and raster to data/eichenbaum2016/AJF027/CDEF2/AJF027_CDEF2_spike_raster.png\n",
      "Saved 55 neurons to data/eichenbaum2016/AJF027/CDEF3/AJF027_CDEF3.pkl and raster to data/eichenbaum2016/AJF027/CDEF3/AJF027_CDEF3_spike_raster.png\n",
      "Saved 40 neurons to data/eichenbaum2016/AJF027/EF1/AJF027_EF1.pkl and raster to data/eichenbaum2016/AJF027/EF1/AJF027_EF1_spike_raster.png\n",
      "Saved 41 neurons to data/eichenbaum2016/AJF027/EF2/AJF027_EF2.pkl and raster to data/eichenbaum2016/AJF027/EF2/AJF027_EF2_spike_raster.png\n",
      "Saved 56 neurons to data/eichenbaum2016/AJF027/EF3/AJF027_EF3.pkl and raster to data/eichenbaum2016/AJF027/EF3/AJF027_EF3_spike_raster.png\n",
      "Saved 55 neurons to data/eichenbaum2016/AJF033/CD2/AJF033_CD2.pkl and raster to data/eichenbaum2016/AJF033/CD2/AJF033_CD2_spike_raster.png\n",
      "Saved 51 neurons to data/eichenbaum2016/AJF033/CD3/AJF033_CD3.pkl and raster to data/eichenbaum2016/AJF033/CD3/AJF033_CD3_spike_raster.png\n",
      "Saved 19 neurons to data/eichenbaum2016/AJF033/CD3EF1/AJF033_CD3EF1.pkl and raster to data/eichenbaum2016/AJF033/CD3EF1/AJF033_CD3EF1_spike_raster.png\n",
      "Saved 54 neurons to data/eichenbaum2016/AJF033/CDEF1/AJF033_CDEF1.pkl and raster to data/eichenbaum2016/AJF033/CDEF1/AJF033_CDEF1_spike_raster.png\n",
      "Saved 48 neurons to data/eichenbaum2016/AJF033/CDEF2/AJF033_CDEF2.pkl and raster to data/eichenbaum2016/AJF033/CDEF2/AJF033_CDEF2_spike_raster.png\n",
      "Saved 46 neurons to data/eichenbaum2016/AJF033/CDEF3/AJF033_CDEF3.pkl and raster to data/eichenbaum2016/AJF033/CDEF3/AJF033_CDEF3_spike_raster.png\n",
      "Saved 57 neurons to data/eichenbaum2016/AJF033/EF1/AJF033_EF1.pkl and raster to data/eichenbaum2016/AJF033/EF1/AJF033_EF1_spike_raster.png\n",
      "Saved 53 neurons to data/eichenbaum2016/AJF033/EF2/AJF033_EF2.pkl and raster to data/eichenbaum2016/AJF033/EF2/AJF033_EF2_spike_raster.png\n",
      "Saved 39 neurons to data/eichenbaum2016/AJF033/EF3/AJF033_EF3.pkl and raster to data/eichenbaum2016/AJF033/EF3/AJF033_EF3_spike_raster.png\n",
      "Saved 35 neurons to data/eichenbaum2016/AJF033/EF3CDEF1/AJF033_EF3CDEF1.pkl and raster to data/eichenbaum2016/AJF033/EF3CDEF1/AJF033_EF3CDEF1_spike_raster.png\n",
      "\n",
      "Completed saving all sessions to data/eichenbaum2016\n"
     ]
    }
   ],
   "source": [
    "# Save all sessions to pkl files with correct directory structure and spike raster PNGs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use relative path from workspace, or absolute if /data exists\n",
    "if os.path.exists('/data'):\n",
    "    output_base_dir = '/data/eichenbaum2016'\n",
    "else:\n",
    "    # Relative to workspace\n",
    "    output_base_dir = 'data/eichenbaum2016'\n",
    "\n",
    "# Process each session and save\n",
    "for file_path in mat_files:\n",
    "    mat = None\n",
    "    units = None\n",
    "    fig = None\n",
    "    try:\n",
    "        # Load one file at a time\n",
    "        mat = scipy.io.loadmat(file_path, struct_as_record=False, squeeze_me=True)\n",
    "        \n",
    "        if 'unitdata' not in mat:\n",
    "            print(f\"Skipping {file_path}: no unitdata\")\n",
    "            del mat\n",
    "            gc.collect()\n",
    "            continue\n",
    "            \n",
    "        units = mat['unitdata'].units\n",
    "        \n",
    "        # Extract session info from path\n",
    "        path_parts = Path(file_path).parts\n",
    "        animal_id = path_parts[-3] if len(path_parts) >= 3 else \"unknown\"\n",
    "        session_id = path_parts[-2] if len(path_parts) >= 2 else \"unknown\"\n",
    "        \n",
    "        # Create output directory structure\n",
    "        output_dir = Path(output_base_dir) / animal_id / session_id\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Create output filenames (using session name)\n",
    "        pkl_filename = f\"{animal_id}_{session_id}.pkl\"\n",
    "        png_filename = f\"{animal_id}_{session_id}_spike_raster.png\"\n",
    "        pkl_path = output_dir / pkl_filename\n",
    "        png_path = output_dir / png_filename\n",
    "        \n",
    "        # Extract neurons with their actual names\n",
    "        neurons = {}\n",
    "        for i in range(len(units)):\n",
    "            unit = units[i]\n",
    "            if hasattr(unit, 'ts'):\n",
    "                spiketimes = unit.ts.flatten()  # spike times in seconds\n",
    "                \n",
    "                # Get neuron name - use actual name from mat file if available\n",
    "                if hasattr(unit, 'name') and unit.name:\n",
    "                    name = unit.name if isinstance(unit.name, str) else str(unit.name)\n",
    "                else:\n",
    "                    # Fallback to generated name if no name in mat file\n",
    "                    name = f\"{animal_id}_{session_id}_cell{i+1}\"\n",
    "                \n",
    "                neurons[name] = spiketimes\n",
    "                # Note: keep spiketimes in memory for plotting, will clear after\n",
    "        \n",
    "        # Save to pkl file\n",
    "        with open(pkl_path, 'wb') as f:\n",
    "            pickle.dump(neurons, f)\n",
    "        \n",
    "        # Create and save spike raster plot\n",
    "        if len(neurons) > 0:\n",
    "            fig = plt.figure(figsize=(12, max(len(neurons)*0.25 + 2, 4)))\n",
    "            plt.eventplot([spiketimes for spiketimes in neurons.values()], \n",
    "                          orientation='horizontal', \n",
    "                          colors='black', \n",
    "                          lineoffsets=1,\n",
    "                          linelengths=0.9)\n",
    "            plt.yticks(range(1, len(neurons)+1), list(neurons.keys()))\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Neuron\")\n",
    "            plt.title(f\"Spike raster: {animal_id}_{session_id} ({len(neurons)} neurons)\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(png_path, dpi=150, bbox_inches='tight')\n",
    "            plt.close(fig)  # Close figure to free memory\n",
    "            fig = None\n",
    "        \n",
    "        print(f\"Saved {len(neurons)} neurons to {pkl_path} and raster to {png_path}\")\n",
    "        \n",
    "        # Clear intermediate variables\n",
    "        del neurons\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "    finally:\n",
    "        # Explicitly release memory after processing each file\n",
    "        if fig is not None:\n",
    "            plt.close(fig)\n",
    "        if units is not None:\n",
    "            del units\n",
    "        if mat is not None:\n",
    "            del mat\n",
    "        # Force garbage collection to free memory\n",
    "        gc.collect()\n",
    "\n",
    "print(f\"\\nCompleted saving all sessions to {output_base_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f7dda98",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/bytedance/Documents/PHD/datasets/2016_Eichenbaum/AJF023/CD1/AJF023CD1SpksEvsSimple.mat'\n",
    "\n",
    "mat = scipy.io.loadmat(file_path, struct_as_record=False, squeeze_me=True)\n",
    "units = mat['unitdata'].units\n",
    "\n",
    "neurons = {}\n",
    "for i in range(len(units)):\n",
    "    unit = units[i]\n",
    "    spiketimes = unit.ts.flatten()  # spike times in 'ts' field\n",
    "    name = f\"AJF023_CD1_cell{i+1}\"\n",
    "    if hasattr(unit, 'name') and unit.name:\n",
    "        name = unit.name if isinstance(unit.name, str) else unit.name[0]\n",
    "    neurons[name] = spiketimes\n",
    "\n",
    "with open('single_session_neurons.pkl', 'wb') as f:\n",
    "    pickle.dump(neurons, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae250b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
